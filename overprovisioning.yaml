apiVersion: v1
kind: Namespace
metadata:
  name: overprovisioning
---
kind: ServiceAccount
apiVersion: v1
metadata:
  name: cluster-proportional-autoscaler-sa
  namespace: overprovisioning
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: cluster-proportional-autoscaler
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["list", "watch"]
  - apiGroups: [""]
    resources: ["replicationcontrollers/scale"]
    verbs: ["get", "update"]
  - apiGroups: ["extensions","apps"]
    resources: ["deployments/scale", "replicasets/scale"]
    verbs: ["get", "update"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get", "create"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: cluster-proportional-autoscaler
subjects:
  - kind: ServiceAccount
    name: cluster-proportional-autoscaler-sa
    namespace: overprovisioning
roleRef:
  kind: ClusterRole
  name: cluster-proportional-autoscaler
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: overprovisioning
value: -1
globalDefault: false
description: "Priority class used by overprovisioning."
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: overprovisioning
  namespace: overprovisioning
spec:
  replicas: 1
  selector:
    matchLabels:
      run: overprovisioning
  template:
    metadata:
      labels:
        run: overprovisioning
    spec:
      priorityClassName: overprovisioning
      containers:
      - name: reserve-resources
        image: k8s.gcr.io/pause
        resources:
          requests:
            cpu: 1100m
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cas-schedule-active
  namespace: overprovisioning
data:
  ladder: |-
    {"nodesToReplicas":[[0,1],[5,2],[10,3],[15,4],[20,5],[25,6],[100,10]]}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cas-schedule-night-and-weekend
  namespace: overprovisioning
data:
  ladder: |-
    {"nodesToReplicas":[[0,0]]}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cas-schedule-day
  namespace: overprovisioning
data:
  ladder: |-
    {"nodesToReplicas":[[0,1],[5,2],[10,3],[15,4],[20,5],[25,6],[100,10]]}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cas-schedule-script-night-and-weekend
  namespace: overprovisioning
data:
  configmap.sh: |
    #!/usr/bin/env sh

    # This script replaces the currently active configmap with another available one.

    set -o errexit
    set -o nounset
    set -o pipefail

    main() {

        kubectl get cm "cas-schedule-night-and-weekend" -n "" -o yaml | yq e '.metadata.name = "cas-schedule-active"' - | kubectl replace --force -f -
    }

    main "$@"
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: cas-schedule-script-day
  namespace: overprovisioning
data:
  configmap.sh: |
    #!/usr/bin/env sh

    # This script replaces the currently active configmap with another available one.

    set -o errexit
    set -o nounset
    set -o pipefail

    main() {

        kubectl get cm "cas-schedule-day" -n "" -o yaml | yq e '.metadata.name = "cas-schedule-active"' - | kubectl replace --force -f -
    }

    main "$@"
---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: cronjob-cas-night-and-weekend
  namespace: overprovisioning
spec:
  failedJobsHistoryLimit: 1
  successfulJobsHistoryLimit: 1
  schedule: "0 18 * * 1-5"
  jobTemplate:
    spec:
      template:
        metadata:
        spec:
          serviceAccountName: cluster-proportional-autoscaler-sa
          securityContext:
            runAsUser: 1001
            runAsGroup: 1001
            fsGroup: 1001
          containers:
          - image: "ghcr.io/codecentric/cluster-overprovisioner-helper:latest"
            imagePullPolicy: "Always"
            name: night-and-weekend
            command: ["/app/configmap.sh"]
            volumeMounts:
              - name: script
                mountPath: /app/
              - name: tmp
                mountPath: /tmp/
          restartPolicy: Never
          volumes:
            - name: script
              configMap:
                name: cas-schedule-script-night-and-weekend
                defaultMode: 0777
            - name: tmp
              emptyDir: {}
---
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: cronjob-cas-day
  namespace: overprovisioning
spec:
  failedJobsHistoryLimit: 1
  successfulJobsHistoryLimit: 1
  schedule: "0 7 * * 1-5"
  jobTemplate:
    spec:
      template:
        metadata:
          labels: 
            helm.sh/chart: cluster-overprovisioner-0.5.0
            app.kubernetes.io/version: "1.16.0"
            app.kubernetes.io/managed-by: Helm
        spec:
          serviceAccountName: cluster-proportional-autoscaler-sa
          securityContext:
            runAsUser: 1001
            runAsGroup: 1001
            fsGroup: 1001
          containers:
          - image: "ghcr.io/codecentric/cluster-overprovisioner-helper:latest"
            imagePullPolicy: "Always"
            name: day
            command: ["/app/configmap.sh"]
            volumeMounts:
              - name: script
                mountPath: /app/
              - name: tmp
                mountPath: /tmp/
          restartPolicy: Never
          volumes:
            - name: script
              configMap:
                name: cas-schedule-script-day
                defaultMode: 0777
            - name: tmp
              emptyDir: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: overprovisioning-autoscaler
  namespace: overprovisioning
  labels:
    app: overprovisioning-autoscaler
spec:
  selector:
    matchLabels:
      app: overprovisioning-autoscaler
  replicas: 1
  template:
    metadata:
      labels:
        app: overprovisioning-autoscaler
    spec:
      containers:
        - image: gcr.io/google_containers/cluster-proportional-autoscaler-amd64:1.7.1
          name: autoscaler
          command:
            - ./cluster-proportional-autoscaler
            - --namespace=overprovisioning
            - --configmap=cas-schedule-active
            - --target=deployment/overprovisioning
            - --logtostderr=true
            - --v=2
      serviceAccountName: cluster-proportional-autoscaler-sa
